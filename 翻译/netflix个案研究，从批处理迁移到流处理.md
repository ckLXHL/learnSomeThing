# Migrating Batch ETL to Stream Processing: A Netflix Case Study with Kafka and Flink

# Netflix 基于kafka和flink的个案研究：从批处理迁移到流处理

## 要点

* 从批量ETL转向流数据处理时，必须做出许多决策和权衡。工程师不应该因为流处理技术的普及而“*流化*所有的处理”
* Netflix在这里介绍的研究案例，已经迁移到Apache Flink。这项技术的选择是基于实时事件处理的要求以及对窗口定制（customisation of windowing）的广泛支持。
* 在迁移过程中遇到了许多挑战，例如从实时数据源获取数据，管理侧（元数据）输入，处理数据恢复和无序的事件和增加的运维负担
* 在使用流处理方面取得了明显的商业成功，其中包括利用最新数据培训机器学习算法的机会。
* 在实施流处理方面也取得了技术上的成功，例如节省存储成本的能力，以及与其他实时系统的集成

>文章内容比较早，是17年7月时QCon大会上的分享，对于不了解的人应该算一个科普

2017年QCon纽约大会上，Shriya Arora分享了《使用流式数据集个性化Netflix》，并讨论了最近Netflix数据处理作业从批量式ETL传统方法向使用Apache Flink进行流式处理的试验和磨难。

Netflix的高级数据工程师[Arora](https://www.linkedin.com/in/shriyaarora/)说，演示的关键目标是帮助观众确定流处理数据是否有助于解决传统ETL（抽取 - 转换 - 加载）批处理作业时可能遇到的问题。除此之外，她还讨论了从批处理转向流式处理时必须做出的核心决策和权衡。 Arora明确强调“批处理没有死亡”，虽然有许多流处理引擎，但没有单一的最佳解决方案。

Netflix的核心任务，是通过使用户可以随时随地观看个性化视频内容，来提升用户体验。在提供这种个性化体验的过程中，Netflix每天从190个不同国家的1亿多活跃会员处理4500亿个不同的事件，每天查看1.25亿小时的内容。 

Netflix系统使用[微服务架构风格](https://www.infoq.com/presentations/netflix-failure-multiple-regions)，服务通过远程过程调用（RPC）和消息传递进行通信。生产系统拥有一个大型的[Apache Kafka](https://kafka.apache.org)集群，部署了700多个Topic，用于管理消息传输并提供数据处理管道。

在Netflix中，数据工程与分析（DEA）团队和Netflix Research负责运行个性化系统。在高层次上，微服务应用程序实例发出用户和系统驱动的数据事件，这些事件在Netflix Keystone数据管道中收集 - 这是用于业务和产品分析的PB级实时事件流处理系统。

传统的批量数据处理通过将这些数据存储在Amazon S3对象存储服务上运行的Hadoop分布式文件系统（HDFS）中进行，并使用Apache Spark，Pig，Hive或Hadoop进行处理。

批处理后的数据存储在Elasticsearch等表tables或索引器indexers中供研究团队，下游系统或仪表板应用程序使用。流处理也是通过使用Apache Kafka将数据流式传输到Apache Flink或Spark Streaming来进行的。

>下游系统类似于我们的fastdev，月光宝盒，大数据系统等。仪表盘系统可以理解为我们的把脉实时监控，大数据实时监控。

在讨论主题之前，Arora首先提醒观众不要“将所有的东西都流化”。

从商业角度看，使用流处理有明显的优势，包括有机会利用最新数据来训练机器学习算法，为新发布的市场营销提供创新，并为新型机器学习算法创造机会。

流处理还有技术上的优势，如节省存储成本的能力（因为原始数据不需要以原始形式存储），更快的纠错周转时间（长时间运行的批处理作业在失败时可能会导致严重的延迟），关键个性化指标的实时审核以及与其他实时系统的集成。

实施流处理的核心挑战是选择合适的引擎。

需要关注的第一个关键问题是将数据作为基于事件的数据流进行处理还是采用*微*批处理。

在Arora看来，*微*批处理实际上只是批量处理的一个子集：一个批处理的时间单位可能会从传统批处理的一天缩短到几小时或几分钟。

但是微批处理仍然是在数据全集上运行的过程而不是实际的事件。

如果简单地要求比目前提供的处理更快，并且该公司已经投入了大量资金在批处理上面，那么迁移到微批处理可能是最合适和最具成本效益的解决方案。

挑选流处理引擎的下一个挑战是要思考，哪些功能对于解决现有的问题最为重要。

这些需要解决的问题，很可能不是在最初的头脑风暴会议上想到的哪些问题 - 通常只有在深入调查后才能深入了解问题和数据。 A

Arora的个例研究要求“会话化sessionization”（session-based windowing基于会话的窗口）。

每个引擎都通过不同的机制在不同程度上支持此功能。

最终，Netflix为Arora的批处理作业迁移选择了Apache Flink，因为它与Spark Streaming相比为窗口定制提供了出色的支持（注：支持Spark结构化流和高级会话处理的新API在Apache Spark 2.2.0，于2017年7月发布，即在此分享发布后发布）。

需要关注的另一个问题是实现是否需要lambda体系结构。

这种体系结构（流处理）不应与AWS Lambda或无服务器技术混淆 - 在数据处理领域，lambda体系结构旨在通过结合批处理和流处理的优点处理大量数据。

这种体系结构方法试图通过创建批量图层来平衡延迟，吞吐量和容错能力，该批量图层提供全面且准确的批量数据视图，同时模拟实现用于实时流处理的*快速层*以提供潜在的不完整但及时的在线数据。

可能情况是现有的批处理作业只需要用*快速层*进行扩充，如果是这种情况，那么选择同时支持两种处理图层的lambda体系结构的数据处理引擎可以促进代码重用。

选择流处理引擎时需要注意的几个其他问题包括：

在你的公司内其他团队使用什么？如果对特定技术有很大投资，则通常可以利用现有的部署和运维知识。

您公司内现有ETL系统的前景如何？一项新技术是否可以轻松适应现有的源代码和风格？

学习曲线有什么要求？你使用什么引擎进行批处理，什么是最广泛采用的编程语言？

之后的分享探讨了将Netflix批处理ETL作业迁移到流处理ETL过程。

 Netflix DEA团队以前使用批量式ETL作业分析Netflix应用程序中的播放源和发现来源，这些作业可能需要超过八个小时才能完成。
 
 播放来源是用户启动播放的内容在Netflix应用程序主页中的位置。
 
 发现来源是用户发现要观看的新内容在主页上的位置。 
 
 DEA团队的最终目标是学习如何优化主页以最大限度地让用户发现内容并播放内容，同时改进动作发生和分析之间过长的24小时延迟。
 
 实时处理可以缩短动作发生和分析动作之间的时间差。

 针对Netflix需要更深入地揭示“发现来源”这个问题，她认为要选择的流处理引擎必须能够：
 1. 处理高吞吐量的数据（全球用户目前每天产生大约1亿次发现/回放事件）;
 2. 通过重客户端（RPC式）与微软服务进行通信，以增强最初的事件;
 3. 与Netflix平台生态系统进行整合，例如服务发现;
 4. 具有集中的日志管理和警报;
 5. 并且允许缓慢改变的数据的side inputs（例如，包含电影元数据或国家人口统计的维度或元数据表）。

最终，Arora和她的团队选择了Apache Flink，并提供了一系列支持技术：

* Apache Kafka充当消息总线;
* Apache Hive使用类似SQL的接口提供数据汇总，查询和分析（尤其适用于这种情况下的元数据）;
* Amazon S3用于在HDFS中存储数据;
* 用于整合到更广泛Netflix生态系统的Netflix OSS栈;
* 用于作业调度和执行的Apache Mesos;
* Spinnaker用于持续交付。

以下是关于"发现来源"管道的示意图：

![Source-of-descovery pipeline](https://lh3.googleusercontent.com/SgPH2qtthe3dtfCTG4YiwGcCw5zkLAqBf5QnY2lSo4N05juVaniuuPplMVltcMdrqGd5dn6q5vyctLVbMOnyzNJnx1wk4UyC1I2Lo1PYCbc7zTE4oRfdgPaX9jbzvZ6QlFExPcnp)

Arora概述了DEA团队在迁移过程中面临的挑战：

1. 从实时来源获取数据：

正在迁移的作业需要访问每个播放事件的用户的完整观看历史记录。

这在流处理的概念上很容易实现，因为与Netflix堆栈的集成和数据处理的实时性，意味着每个事件处理时都需要一个类似RPC的简单调用。

但是，由于Apache Flink流处理应用程序是使用Java API编写的，并且Netflix OSS堆栈也是使用Java编写的，所以确保两个应用程序库（管理所谓的“JAR hell”）之间的兼容性有时是一项挑战。

2. side inputs：

流处理作业中所需的每个元数据项，可以通过类似于从直播源获取数据的方式获得。

但是，这需要很多网络调用，并且最终会导致资源的使用非常低效。

解决方案是将元数据缓存到每个流处理实例的内存中，并且每15分钟刷新一次数据。

3. 数据恢复：

由于基础架构问题导致批处理作业失败时，重新运行作业很容易，因为数据仍存储在底层数据库（即HDFS）中。这不一定是流处理的情况，因为原始事件可以在处理时被丢弃。

在Netflix生态系统中，存储原始事件的消息总线（Kafka）的TTL策略（超时时间）比较为激进 - 由于体积的原因，超时时间大概四到六个小时。

相应地，如果流处理作业失败并且在TTL时间限制内未检测到并修复，则可能会发生数据丢失。

此问题的解决方案是将原始数据额外存储在HDFS中一段有限的时间（一到两天）以便于重放。

4. 事件没有顺序：

在发生处理管线故障时，数据恢复过程（以及事件的重新加载）将意味着“旧”数据将与实时数据混合在一起。

需要解决的问题在于迟到的数据必须正确地与事件产生的时间相关联。

DEA团队选择实现了时间窗口，同时后处理post-process数据以确保处理结果关联了正确的时间事件上下午。

5. 增加监控和警报：

如果发生处理管线的故障，必须尽快通知团队。

未能触发及时的警报可能会导致数据丢失。

创建有效的监控，日志记录和警报实施至关重要。

## 总结

Arora说，虽然从批量ETL迁移到流处理的过程，使得业务和技术都得到了很大的提升，但也有许多挑战和经教训。

采用流处理的工程师应准备支付先驱税（需要踩坑），因为大多数传统的ETL是批量处理，并且针对流数据的机器学习模型是相对较新的领域。

数据处理团队还将面临高优先级的运维问题 - 如being on call and handling outages处理中断 - 即“批处理失败必须紧急定位，流处理失败必须立即解决”。

必须对弹性基础设施进行投资，并且团队还应培养有效的监控和警报，并创建持续交付管道，以促进数据处理应用程序的快速迭代和部署。